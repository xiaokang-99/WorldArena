# WorldArena: A Unified Benchmark for Evaluating Perception and Functional Utility of Embodied World Models

</div>

<div align="center">

<a href="https://world-arena.ai/">
  <img src="https://img.shields.io/badge/Website-WorldArena-2563eb?style=for-the-badge&logo=googlechrome&logoColor=white">
</a>

<a href="https://arxiv.org/abs/2602.08971">
  <img src="https://img.shields.io/badge/Paper-arXiv-b31b1b?style=for-the-badge&logo=arxiv&logoColor=white">
</a>

<a href="https://huggingface.co/spaces/WorldArena/WorldArena">
  <img src="https://img.shields.io/badge/Leaderboard-HuggingFace-ffcc00?style=for-the-badge&logo=huggingface&logoColor=ffcc00">
</a>

</div>

<div align="center">

**Yu ShangÂ¹Â§\*** Â· Zhuohang LiÂ¹\* Â· Yiding MaÂ¹\* Â· Weikang SuÂ¹\* Xin Jinâ€¡ Â· Ziyou WangÂ¹â€¡ Â· Lei JinÂ¹ Â· Xin ZhangÂ¹ Â· Yinzhou TangÂ¹ Â·  Haisheng SuÂ² Â· Chen GaoÂ¹ Â· 

Wei WuÂ¹ Â· Xihui LiuÂ³ Â· Dhruv Shahâ´ Â·  Zhaoxiang Zhangâµ Â· Zhibo Chenâ¶ Â· Jun ZhuÂ¹ Â· Yonghong Tianâ· Â·  Tat-Seng Chuaâ¸ Â· Wenwu ZhuÂ¹ Â· **Yong LiÂ¹â€ **

Â¹ Tsinghua Â· Â² SJTU Â· Â³ HKU Â· â´ Princeton Â·  âµ CAS Â· â¶ USTC Â· â· PKU Â· â¸ NUS  

\* Equal contribution Â· â€¡ Equal contribution Â· Â§ Project lead Â· â€  Corresponding author

</div>

## Table of Contents

- [Updates](#updates)
- [Overview](#overview)
- [Dataset](#dataset)
- [Video Quality Evaluation](#video_quality_evaluation)
- [Embodied Task Evaluation](#embodied_task_evaluation)
- [Leaderboard](#leaderboard)
- [Submission](#submission)
- [Human Evaluation](#human_evaluation)
- [Citation](#citation)


## ğŸ“¢ Updates

- [2026/0213] Initial release.
- [2026/0213] Leaderboard release.


## ğŸ” Overview

WorldArena is a unified benchmark designed to systematically evaluate embodied world models across both **perceptual** and **functional** dimensions. WorldArena assesses models through **(1) video perception quality**, measured with sixteen metrics across six sub-dimensions; **(2) embodied task functionality**, which evaluates world models as synthetic data engines, policy evaluators, and action planners; **(3) human evaluations**, including overall quality, physics adherence, instruction following and head-to-head win rate. Furthermore, we propose **EWMScore**, a holistic metric integrating multi-dimensional performance into a single interpretable index. This work provides a framework for tracking progress toward truly functional world models in embodied AI.


## ğŸ“¦ Dataset
Coming soon.


## ğŸ¬ Video Quality Evaluation
<div align="center">

<img src="assets/video_eval.png" width="85%">

</div>

## ğŸ¤– Embodied Task Evaluation

<div align="center">

<img src="assets/task_eval.png" width="85%">

</div>
Coming soon.

## ğŸ† Leaderboard

The official WorldArena leaderboard is hosted on Hugging Face: [![Leaderboard](https://img.shields.io/badge/Leaderboard-HuggingFace-2D2D2D?style=flat&logo=huggingface&logoColor=ffcc00)](https://huggingface.co/spaces/WorldArena/WorldArena). It provides standardized evaluation results across video perception quality, embodied task functionality, and the unified EWMScore. We welcome community submissions to benchmark new embodied world models under a fair and reproducible protocol. Join us in advancing truly functional world models for embodied AI.


## ğŸ“¤ Submission
Coming soon.

## ğŸ‘¥ Human Evaluation
Be part of shaping the future of embodied world models!  ğŸ‘‰ **Start here:**  [Human Evaluation](https://sd64n7jjtvotb9m1apn80.apigateway-cn-beijing.volceapi.com/)

We invite you to participate in our human evaluation by providing your judgment about generated videos â€” it only takes a few minutes. Your feedback helps us uncover hidden failure cases and align automated metrics with real human perception. Every contribution strengthens a more trustworthy and community-driven leaderboard.


## ğŸ™Œ Acknowledgement


## ğŸ“– Citation

